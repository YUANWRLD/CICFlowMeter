{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train_data_v1.csv')\n",
    "\n",
    "columns = ['flow_duration', 'fwd_pkt_len_max', 'fwd_pkt_len_mean',\n",
    "       'fwd_pkt_len_std', 'fwd_seg_size_avg', 'flow_iat_mean', 'flow_iat_max',\n",
    "       'flow_iat_std', 'fwd_iat_tot', 'fwd_iat_max', 'fwd_iat_mean',\n",
    "       'fwd_iat_std', 'bwd_iat_tot', 'bwd_iat_max', 'bwd_iat_std',\n",
    "       'fin_flag_cnt', 'rst_flag_cnt', 'init_fwd_win_byts', 'win_byts_tot',\n",
    "       'fwd_win_tot', 'fwd_win_mean', 'win_byts_std', 'fwd_win_std',\n",
    "       'fwd_win_max', 'win_byts_min', 'fwd_win_min', 'zero_win_cnt',\n",
    "       'idle_max', 'idle_mean', 'idle_std']\n",
    "\n",
    "data_x = df[columns]\n",
    "data_y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9989646501996746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DCmodel = DecisionTreeClassifier()\n",
    "DCmodel.fit(x_train, y_train)\n",
    "y_predict_DC = DCmodel.predict(x_test)\n",
    "print('accuracy : '+ str(metrics.accuracy_score(y_test, y_predict_DC)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9994083715426711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFmodel = RandomForestClassifier(criterion='entropy')\n",
    "RFmodel.fit(x_train, y_train)\n",
    "y_predict_RF = RFmodel.predict(x_test)\n",
    "print('accuracy : '+ str(metrics.accuracy_score(y_test, y_predict_RF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1=> accuracy : 0.9986688359710102\n",
      "K = 3=> accuracy : 0.9987181383424543\n",
      "K = 5=> accuracy : 0.9983730217423458\n",
      "K = 7=> accuracy : 0.9976827885421289\n",
      "K = 9=> accuracy : 0.9973869743134645\n",
      "K = 11=> accuracy : 0.9971404624562441\n",
      "K = 13=> accuracy : 0.9966967411132476\n",
      "K = 15=> accuracy : 0.9963516245131391\n",
      "K = 17=> accuracy : 0.9962037173988069\n",
      "K = 19=> accuracy : 0.9959079031701424\n",
      "K = 21=> accuracy : 0.995562786570034\n",
      "K = 23=> accuracy : 0.9953162747128137\n",
      "K = 25=> accuracy : 0.9951190652270374\n",
      "K = 27=> accuracy : 0.9952669723413696\n",
      "K = 29=> accuracy : 0.9949711581127052\n",
      "K = 31=> accuracy : 0.9949218557412611\n",
      "K = 33=> accuracy : 0.9944288320268205\n",
      "K = 35=> accuracy : 0.9941823201696002\n",
      "K = 37=> accuracy : 0.994034413055268\n",
      "K = 39=> accuracy : 0.9936892964551595\n",
      "K = 41=> accuracy : 0.993294877483607\n",
      "K = 43=> accuracy : 0.9927032490262782\n",
      "K = 45=> accuracy : 0.9925553419119459\n",
      "K = 47=> accuracy : 0.9923088300547256\n",
      "\n",
      "Best K = 3,accuracy = 0.9987181383424543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "best_i = 1\n",
    "best_acc = 0\n",
    "for i in  range(1, 49, 2):\n",
    "    KNNmodel = KNeighborsClassifier(n_neighbors=i)\n",
    "    KNNmodel.fit(x_train, y_train)\n",
    "    y_predict_KNN = KNNmodel.predict(x_test)\n",
    "    score = metrics.accuracy_score(y_test, y_predict_KNN)\n",
    "    if score > best_acc:\n",
    "        best_acc = score\n",
    "        best_i = i\n",
    "    print('K = ' + str(i) + '=> accuracy : '+ str(score))\n",
    "print('\\nBest K = ' + str(best_i) + ',accuracy = ' + str(best_acc))\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=best_i)\n",
    "KNNmodel.fit(x_train, y_train)\n",
    "y_predict_KNN = KNNmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9991618596854509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "XGBoostmodel = GradientBoostingClassifier()\n",
    "XGBoostmodel.fit(x_train, y_train)\n",
    "y_predict_XGBoost = XGBoostmodel.predict(x_test)\n",
    "print('accuracy : '+ str(metrics.accuracy_score(y_test, y_predict_XGBoost)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9561701917862249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "NBmodel = GaussianNB()\n",
    "NBmodel.fit(x_train, y_train)\n",
    "y_predict_NB = NBmodel.predict(x_test)\n",
    "print('accuracy : '+ str(metrics.accuracy_score(y_test, y_predict_NB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "precision = [0.99991006 0.99809614 0.99758162]\n",
      "recall = [0.99982014 0.99714693 0.99858786]\n",
      "f1-score = [0.9998651  0.99762131 0.99808448]\n",
      "True positive rate : [0.99982014 0.99714693 0.99858786]\n",
      "False positive rate : [0.00010913 0.00049761 0.00078298]\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "precision = [0.99991008 0.99881094 0.99878959]\n",
      "recall = [1.         0.99857347 0.99878959]\n",
      "f1-score = [0.99995504 0.99869219 0.99878959]\n",
      "True positive rate : [1.         0.99857347 0.99878959]\n",
      "False positive rate : [0.00010913 0.000311   0.00039149]\n",
      "\n",
      "\n",
      "KNeighborsClassifier\n",
      "precision = [0.99964038 0.99833214 0.99697763]\n",
      "recall = [0.99991007 0.99619591 0.99818439]\n",
      "f1-score = [0.99977521 0.99726288 0.99758065]\n",
      "True positive rate : [0.99991007 0.99619591 0.99818439]\n",
      "False positive rate : [0.00043654 0.0004354  0.00097873]\n",
      "\n",
      "\n",
      "XGBoostClassifier\n",
      "precision = [0.99991008 0.99809796 0.99838579]\n",
      "recall = [1.         0.99809796 0.99818439]\n",
      "f1-score = [0.99995504 0.99809796 0.99828508]\n",
      "True positive rate : [1.         0.99809796 0.99818439]\n",
      "False positive rate : [0.00010913 0.00049761 0.00052199]\n",
      "\n",
      "\n",
      "NaivebayesClassifier\n",
      "precision = [0.96745159 0.8792633  1.        ]\n",
      "recall = [0.95692446 0.91940086 0.98567682]\n",
      "f1-score = [0.96215923 0.89888424 0.99278675]\n",
      "True positive rate : [0.95692446 0.91940086 0.98567682]\n",
      "False positive rate : [0.03907017 0.03302855 0.        ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def print_precision_recall(cm):\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = FP/(FP+TN)\n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    f_measure = 2*(recall*precision)/(recall+precision)\n",
    "    print('precision = ' + str(precision))\n",
    "    print('recall = ' + str(recall))\n",
    "    print('f1-score = ' + str(f_measure))\n",
    "    print('True positive rate : ' + str(TPR))\n",
    "    print('False positive rate : ' + str(FPR))\n",
    "\n",
    "cm_DC = confusion_matrix(y_test, y_predict_DC)\n",
    "print('DecisionTreeClassifier')\n",
    "print_precision_recall(cm_DC)\n",
    "print('\\n')\n",
    "\n",
    "cm_RF = confusion_matrix(y_test, y_predict_RF)\n",
    "print('RandomForestClassifier')\n",
    "print_precision_recall(cm_RF)\n",
    "print('\\n')\n",
    "\n",
    "cm_KNN = confusion_matrix(y_test, y_predict_KNN)\n",
    "print('KNeighborsClassifier')\n",
    "print_precision_recall(cm_KNN)\n",
    "print('\\n')\n",
    "\n",
    "cm_XGBoost = confusion_matrix(y_test, y_predict_XGBoost)\n",
    "print('XGBoostClassifier')\n",
    "print_precision_recall(cm_XGBoost)\n",
    "print('\\n')\n",
    "\n",
    "cm_NB = confusion_matrix(y_test, y_predict_NB)\n",
    "print('NaivebayesClassifier')\n",
    "print_precision_recall(cm_NB)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型導出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"DCmodel.pickle\", 'wb') as f:\n",
    "    pickle.dump(DCmodel, f)\n",
    "\n",
    "with open(\"RFmodel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(RFmodel, f)\n",
    "\n",
    "with open(\"KNNmodel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(KNNmodel, f)\n",
    "\n",
    "with open(\"XGBoostmodel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(XGBoostmodel, f)\n",
    "\n",
    "with open(\"NBmodel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(NBmodel, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_test.csv\n",
      "----------------------------------\n",
      "Total : 10103\n",
      "predicted benign : 10103\n",
      "predicted slowread : 0\n",
      "predicted slowloris : 0\n",
      "benign accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"RFmodel.pickle\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "test = pd.read_csv(\"./model_data/testdata/normal_simulate_test.csv\")\n",
    "\n",
    "columns = ['flow_duration', 'fwd_pkt_len_max', 'fwd_pkt_len_mean',\n",
    "       'fwd_pkt_len_std', 'fwd_seg_size_avg', 'flow_iat_mean', 'flow_iat_max',\n",
    "       'flow_iat_std', 'fwd_iat_tot', 'fwd_iat_max', 'fwd_iat_mean',\n",
    "       'fwd_iat_std', 'bwd_iat_tot', 'bwd_iat_max', 'bwd_iat_std',\n",
    "       'fin_flag_cnt', 'rst_flag_cnt', 'init_fwd_win_byts', 'win_byts_tot',\n",
    "       'fwd_win_tot', 'fwd_win_mean', 'win_byts_std', 'fwd_win_std',\n",
    "       'fwd_win_max', 'win_byts_min', 'fwd_win_min', 'zero_win_cnt',\n",
    "       'idle_max', 'idle_mean', 'idle_std']\n",
    "\n",
    "test_x = test[columns]\n",
    "\n",
    "num = 0\n",
    "benign = 0\n",
    "read = 0\n",
    "loris = 0\n",
    "for i in model.predict(test_x):\n",
    "    num += 1\n",
    "    if(i == 'benign'):benign += 1\n",
    "    elif(i == 'slowread'):read += 1\n",
    "    elif(i == 'slowloris'):loris += 1\n",
    "\n",
    "print(\"normal_test.csv\")\n",
    "print(\"----------------------------------\")\n",
    "print(\"Total : \" + str(num))\n",
    "print(\"predicted benign : \" + str(benign))\n",
    "print(\"predicted slowread : \" + str(read))\n",
    "print(\"predicted slowloris : \" + str(loris))\n",
    "print('benign accuracy : ' + str(benign/num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slowloris test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slowloris_test.csv\n",
      "----------------------------------\n",
      "Total : 5901\n",
      "predicted benign : 0\n",
      "predicted slowread : 8\n",
      "predicted slowloris : 5893\n",
      "slowloris accuracy : 0.9986442975766819\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"RFmodel.pickle\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "test = pd.read_csv(\"./model_data/testdata/slowloris_test.csv\")\n",
    "\n",
    "columns = ['flow_duration', 'fwd_pkt_len_max', 'fwd_pkt_len_mean',\n",
    "       'fwd_pkt_len_std', 'fwd_seg_size_avg', 'flow_iat_mean', 'flow_iat_max',\n",
    "       'flow_iat_std', 'fwd_iat_tot', 'fwd_iat_max', 'fwd_iat_mean',\n",
    "       'fwd_iat_std', 'bwd_iat_tot', 'bwd_iat_max', 'bwd_iat_std',\n",
    "       'fin_flag_cnt', 'rst_flag_cnt', 'init_fwd_win_byts', 'win_byts_tot',\n",
    "       'fwd_win_tot', 'fwd_win_mean', 'win_byts_std', 'fwd_win_std',\n",
    "       'fwd_win_max', 'win_byts_min', 'fwd_win_min', 'zero_win_cnt',\n",
    "       'idle_max', 'idle_mean', 'idle_std']\n",
    "\n",
    "test_x = test[columns]\n",
    "\n",
    "num = 0\n",
    "benign = 0\n",
    "read = 0\n",
    "loris = 0\n",
    "for i in model.predict(test_x):\n",
    "    num += 1\n",
    "    if(i == 'benign'):benign += 1\n",
    "    elif(i == 'slowread'):read += 1\n",
    "    elif(i == 'slowloris'):loris += 1\n",
    "\n",
    "print(\"slowloris_test.csv\")\n",
    "print(\"----------------------------------\")\n",
    "print(\"Total : \" + str(num))\n",
    "print(\"predicted benign : \" + str(benign))\n",
    "print(\"predicted slowread : \" + str(read))\n",
    "print(\"predicted slowloris : \" + str(loris))\n",
    "print('slowloris accuracy : ' + str(loris/num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slowread test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slowread_test.csv\n",
      "----------------------------------\n",
      "Total : 5871\n",
      "predicted benign : 0\n",
      "predicted slowread : 5836\n",
      "predicted slowloris : 35\n",
      "slowread accuracy : 0.9940384942939874\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"RFmodel.pickle\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "test = pd.read_csv(\"./model_data/testdata/slowread_test.csv\")\n",
    "\n",
    "columns = ['flow_duration', 'fwd_pkt_len_max', 'fwd_pkt_len_mean',\n",
    "       'fwd_pkt_len_std', 'fwd_seg_size_avg', 'flow_iat_mean', 'flow_iat_max',\n",
    "       'flow_iat_std', 'fwd_iat_tot', 'fwd_iat_max', 'fwd_iat_mean',\n",
    "       'fwd_iat_std', 'bwd_iat_tot', 'bwd_iat_max', 'bwd_iat_std',\n",
    "       'fin_flag_cnt', 'rst_flag_cnt', 'init_fwd_win_byts', 'win_byts_tot',\n",
    "       'fwd_win_tot', 'fwd_win_mean', 'win_byts_std', 'fwd_win_std',\n",
    "       'fwd_win_max', 'win_byts_min', 'fwd_win_min', 'zero_win_cnt',\n",
    "       'idle_max', 'idle_mean', 'idle_std']\n",
    "\n",
    "test_x = test[columns]\n",
    "\n",
    "num = 0\n",
    "benign = 0\n",
    "read = 0\n",
    "loris = 0\n",
    "for i in model.predict(test_x):\n",
    "    num += 1\n",
    "    if(i == 'benign'):benign += 1\n",
    "    elif(i == 'slowread'):read += 1\n",
    "    elif(i == 'slowloris'):loris += 1\n",
    "\n",
    "print(\"slowread_test.csv\")\n",
    "print(\"----------------------------------\")\n",
    "print(\"Total : \" + str(num))\n",
    "print(\"predicted benign : \" + str(benign))\n",
    "print(\"predicted slowread : \" + str(read))\n",
    "print(\"predicted slowloris : \" + str(loris))\n",
    "print('slowread accuracy : ' + str(read/num))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
